# ğŸš€ HashMap CacheLab - Aide-MÃ©moire Rapide

## Structure de Base

```typescript
// NÅ“ud de la liste chaÃ®nÃ©e
CacheEntry {
    key: string
    value: any
    next: CacheEntry | null
    lastAccessed: number     // Pour LRU
    sizeInBytes: number      // Pour gestion RAM
}

// HashMap principale
CacheStore {
    size: number                    // Nombre de buckets (7 â†’ 14 â†’ 28...)
    buckets: CacheEntry[]           // Tableau de listes chaÃ®nÃ©es
    currentMemoryUsage: number      // RAM utilisÃ©e
    MAX_MEMORY: 5MB                 // Limite RAM
    LOAD_FACTOR_THRESHOLD: 0.75    // Seuil rehash
}
```

---

## Fonction de Hachage

```
ClÃ© â†’ SHA-256 â†’ 8 premiers chars â†’ parseInt(hex) â†’ % size â†’ index
```

**Exemple:**
```
"user123" â†’ "a1b2c3d4..." â†’ "a1b2c3d4" â†’ 2712847316 â†’ % 7 â†’ 5
```

---

## OpÃ©rations Principales

### SET (key, value)
```
1. Calculer taille de l'entrÃ©e
2. SI mÃ©moire insuffisante â†’ Ã‰vincer LRU
3. SI load factor > 0.75 â†’ Rehash
4. Calculer index = hash(key) % size
5. InsÃ©rer dans bucket[index]
   - Bucket vide â†’ Nouvelle entrÃ©e
   - ClÃ© existe â†’ Mettre Ã  jour
   - Sinon â†’ Ajouter Ã  la fin de la chaÃ®ne
```

### GET (key)
```
1. index = hash(key) % size
2. Parcourir bucket[index]
3. Si trouvÃ©:
   - Mettre Ã  jour lastAccessed
   - Retourner value
4. Sinon â†’ Retourner null
```

### DELETE (key)
```
1. index = hash(key) % size
2. Parcourir bucket[index]
3. Si trouvÃ©:
   - Soustraire size de currentMemoryUsage
   - Retirer de la chaÃ®ne
   - Retourner true
4. Sinon â†’ Retourner false
```

---

## Gestion des Collisions

**ChaÃ®nage SÃ©parÃ©:**
```
Bucket[2]: [user1] â†’ [config] â†’ [data] â†’ null
```

Deux clÃ©s avec mÃªme hash â†’ mÃªme bucket â†’ liste chaÃ®nÃ©e

---

## Rehashing

**Quand ?** Load Factor = count/size > 0.75

**Comment ?**
```
1. oldSize = size
2. size = size Ã— 2
3. CrÃ©er nouveau tableau de buckets
4. Pour chaque entrÃ©e:
   - Recalculer index avec nouveau size
   - InsÃ©rer dans nouveau bucket
```

**Exemple:**
```
6 entrÃ©es / 7 buckets = 0.857 > 0.75
â†’ Rehash: size = 14
â†’ 6 / 14 = 0.428 < 0.75 âœ“
```

---

## LRU (Least Recently Used)

**Principe:** Garder les entrÃ©es rÃ©cemment utilisÃ©es

**Tracking:**
- Chaque `get()` â†’ `lastAccessed = Date.now()`
- Chaque `set()` â†’ `lastAccessed = Date.now()`

**Ã‰viction:**
```
1. Parcourir TOUS les buckets
2. Trouver entry avec plus petit lastAccessed
3. delete(entry.key)
4. RÃ©pÃ©ter si nÃ©cessaire pour libÃ©rer assez de mÃ©moire
```

---

## Gestion RAM

**Limite:** 5 MB (5,242,880 bytes)

**Estimation taille:**
```
boolean  â†’ 4 bytes
number   â†’ 8 bytes
string   â†’ length Ã— 2 bytes
object   â†’ JSON.stringify(obj).length Ã— 2 bytes
```

**MÃ©canisme:**
```
AVANT chaque set():
  TANT QUE (currentMemory + newEntrySize > 5MB):
    evictLRU()
```

---

## ComplexitÃ©s

| OpÃ©ration | Moyenne | Pire |
|-----------|---------|------|
| set()     | O(1)    | O(n) |
| get()     | O(1)    | O(n) |
| delete()  | O(1)    | O(n) |
| rehash()  | O(n)    | O(n) |
| evictLRU()| O(n)    | O(n) |
| keys()    | O(n)    | O(n) |

---

## Endpoints API

### Cache Operations
```bash
GET    /keys           # Lister toutes les clÃ©s
POST   /keys           # CrÃ©er une clÃ©
GET    /keys/:key      # Lire une clÃ©
PUT    /keys/:key      # Mettre Ã  jour une clÃ©
DELETE /keys/:key      # Supprimer une clÃ©
```

### Debug
```bash
GET  /debug/bucket-size   # Taille du tableau
GET  /debug/load-factor   # Facteur de charge
GET  /debug/count         # Nombre d'entrÃ©es
GET  /debug/memory        # Usage mÃ©moire
POST /debug/reset         # RÃ©initialiser
```

---

## Exemple Complet

```javascript
// 1. CrÃ©er 3 entrÃ©es
set("alice", {age: 30})   // Bucket[3], lastAccessed: 1000
wait(1s)
set("bob", {age: 25})     // Bucket[3], lastAccessed: 2000 (collision!)
wait(1s)
set("charlie", {age: 35}) // Bucket[5], lastAccessed: 3000

// Ã‰tat: Bucket[3]: alice â†’ bob â†’ null
//       Bucket[5]: charlie â†’ null

// 2. AccÃ©der Ã  alice
get("alice")  // lastAccessed: 4000 (mis Ã  jour!)

// 3. Remplir cache avec grandes donnÃ©es
for i in 1..100:
    set("large_" + i, "x" Ã— 50000)  // 50KB

// 4. RÃ©sultat aprÃ¨s Ã©victions LRU
get("bob")      â†’ null (Ã©vincÃ©, lastAccessed = 2000 Ã©tait le plus ancien)
get("charlie")  â†’ null (Ã©vincÃ© ensuite)
get("alice")    â†’ {age: 30} (toujours lÃ  car lastAccessed = 4000)
```

---

## Points Ã  Mentionner

### Forces
âœ… O(1) en moyenne  
âœ… Gestion automatique RAM  
âœ… Ã‰viction intelligente (LRU)  
âœ… ScalabilitÃ© (rehashing)  
âœ… Distribution uniforme (SHA-256)  

### AmÃ©liorations Possibles
ğŸ”§ LRU O(1) avec doubly-linked list  
ğŸ”§ MurmurHash au lieu de SHA-256  
ğŸ”§ TTL pour expiration auto  
ğŸ”§ Statistiques (hits/misses)  

---

## Commandes Utiles

```bash
# Lancer serveur
npm run dev

# Tests automatiques
./test-cache.sh

# Test manuel
curl http://localhost:3000/keys
curl -X POST http://localhost:3000/keys \
  -H "Content-Type: application/json" \
  -d '{"key": "test", "value": "hello"}'
```

---

## Formules Importantes

```
Load Factor = Nombre d'entrÃ©es / Nombre de buckets

Rehash quand: Load Factor > 0.75

Usage mÃ©moire (%) = (currentMemoryBytes / maxMemoryBytes) Ã— 100

Longueur moyenne chaÃ®ne = count / size
```

---

## Questions FrÃ©quentes

**Q: Pourquoi SHA-256 ?**  
R: Distribution uniforme + rÃ©sistance aux collisions intentionnelles

**Q: Pourquoi doubler la taille ?**  
R: Standard pour amortir le coÃ»t du rehashing sur O(1) amorti

**Q: Pourquoi LRU et pas FIFO ?**  
R: LRU garde les donnÃ©es frÃ©quemment accÃ©dÃ©es (meilleur hit rate)

**Q: Que se passe-t-il si une entrÃ©e > 5MB ?**  
R: Le cache se vide complÃ¨tement mais ne peut pas l'insÃ©rer

**Q: ChaÃ®nage vs Probing linÃ©aire ?**  
R: ChaÃ®nage = pas de limite, Probing = meilleure localitÃ© cache

---

**ğŸ“š Docs complÃ¨tes:**
- `EXPLICATION_HASHMAP.md` - Guide dÃ©taillÃ©
- `PRESENTATION_HASHMAP.md` - PrÃ©sentation visuelle


